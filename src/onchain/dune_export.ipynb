{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faef85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, sys, json, time, pathlib, textwrap\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f295292",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Hard dependency only at runtime when actually calling Dune\n",
    "try:\n",
    "    from dune_client.client import DuneClient\n",
    "except Exception:  # pragma: no cover\n",
    "    DuneClient = None  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ff8d5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_yaml(path: str) -> Dict[str, Any]:\n",
    "    import yaml  # local import to avoid forcing PyYAML unless you use this script\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18608a65",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_sql(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4702bf8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fill_params(sql: str, params: Dict[str, str]) -> str:\n",
    "    # Very simple token replacement for {{start}} / {{end}}\n",
    "    for k, v in params.items():\n",
    "        sql = sql.replace(\"{{\" + k + \"}}\", v)\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981df64f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_dune_sql(client: \"DuneClient\", sql: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses dune-client's SQL execution. Some versions expose `client.run_sql(sql)`.\n",
    "    If not available, try `client.execute_sql(sql)` as a fallback.\n",
    "    \"\"\"\n",
    "    if hasattr(client, \"run_sql\"):\n",
    "        res = client.run_sql(sql)  # returns a ResultResponse with .result.rows\n",
    "        rows = res.get(\"result\", {}).get(\"rows\") if isinstance(res, dict) else getattr(res, \"result\", {}).get(\"rows\", [])\n",
    "    elif hasattr(client, \"execute_sql\"):\n",
    "        res = client.execute_sql(sql)\n",
    "        rows = res.get(\"result\", {}).get(\"rows\", [])\n",
    "    else:\n",
    "        raise RuntimeError(\"Your dune-client version does not support run_sql/execute_sql. Please upgrade `dune-client`.\")\n",
    "    if rows is None:\n",
    "        rows = []\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c9532",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def ensure_outdir(p: pathlib.Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1b2d9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def write_parquet(df: pd.DataFrame, out_path: pathlib.Path) -> None:\n",
    "    # If empty, still write a valid file with schema\n",
    "    if df.empty:\n",
    "        # attempt to infer schema-less by adding a dummy row and removing it\n",
    "        df = df.head(0)\n",
    "    df.to_parquet(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1930567",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main() -> int:\n",
    "    ap = argparse.ArgumentParser(description=\"Export on-chain queries from Dune to Parquet.\")\n",
    "    ap.add_argument(\"--jobs\", default=\"analytics/onchain/config/onchain_jobs.yaml\", help=\"YAML with job list\")\n",
    "    ap.add_argument(\"--outdir\", default=\"data/processed/onchain\", help=\"Output directory\")\n",
    "    ap.add_argument(\"--start\", dest=\"start\", default=os.getenv(\"ONCHAIN_DEFAULT_START\", \"\"), help=\"ISO8601, overrides {{start}}\")\n",
    "    ap.add_argument(\"--end\", dest=\"end\", default=os.getenv(\"ONCHAIN_DEFAULT_END\", \"\"), help=\"ISO8601, overrides {{end}}\")\n",
    "    ap.add_argument(\"--job\", dest=\"only\", default=\"\", help=\"Only run a single job name\")\n",
    "    ap.add_argument(\"--sleep\", type=float, default=0.0, help=\"Seconds to sleep between jobs (API courtesy)\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    dune_key = os.getenv(\"DUNE_API_KEY\")\n",
    "    if not dune_key:\n",
    "        print(\"ERROR: DUNE_API_KEY not set (put it in your environment or .env).\", file=sys.stderr)\n",
    "        return 2\n",
    "\n",
    "    cfg = load_yaml(args.jobs)\n",
    "    job_list: List[Dict[str, Any]] = cfg.get(\"jobs\", [])\n",
    "    if args.only:\n",
    "        job_list = [j for j in job_list if j.get(\"name\") == args.only]\n",
    "        if not job_list:\n",
    "            print(f\"ERROR: job '{args.only}' not found in {args.jobs}\", file=sys.stderr)\n",
    "            return 3\n",
    "\n",
    "    # Simple param pack\n",
    "    param_map = {}\n",
    "    if args.start:\n",
    "        param_map[\"start\"] = args.start\n",
    "    if args.end:\n",
    "        param_map[\"end\"] = args.end\n",
    "\n",
    "    client = DuneClient(api_key=dune_key) if DuneClient else None\n",
    "    if client is None:\n",
    "        print(\"ERROR: dune-client is not installed/available. Add it to requirements and reinstall.\", file=sys.stderr)\n",
    "        return 4\n",
    "\n",
    "    outdir = pathlib.Path(args.outdir)\n",
    "    ensure_outdir(outdir)\n",
    "\n",
    "    summary = []\n",
    "    for job in job_list:\n",
    "        name = job[\"name\"]\n",
    "        sql_path = job[\"sql\"]\n",
    "        outfile = job[\"outfile\"]\n",
    "        print(f\"→ {name}: {sql_path}\")\n",
    "\n",
    "        sql = read_sql(sql_path)\n",
    "        sql_filled = fill_params(sql, param_map) if param_map else sql\n",
    "\n",
    "        try:\n",
    "            df = run_dune_sql(client, sql_filled)\n",
    "            out_path = outdir / outfile\n",
    "            write_parquet(df, out_path)\n",
    "            n = len(df)\n",
    "            print(f\"   wrote {n} rows → {out_path}\")\n",
    "            summary.append({\"job\": name, \"rows\": n, \"out\": str(out_path)})\n",
    "        except Exception as e:\n",
    "            print(f\"   ERROR {name}: {e}\", file=sys.stderr)\n",
    "            summary.append({\"job\": name, \"error\": str(e)})\n",
    "        if args.sleep:\n",
    "            time.sleep(args.sleep)\n",
    "\n",
    "    # machine-readable summary for logs\n",
    "    print(json.dumps({\"ok\": True, \"summary\": summary}, indent=2))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    raise SystemExit(main())"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "jupytext,text_representation,kernelspec"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
