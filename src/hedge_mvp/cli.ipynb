{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hedge MVP CLI (backtest + paper rebalancer + funding snapshot + XGB vol trigger)\n",
    "\n",
    "Examples:\n",
    "  # backtest with plots\n",
    "  python -m src.hedge_mvp.cli backtest --symbol BTC/USDT --perp BTC/USDT:USDT --timeframe 1h --limit 1500 --plot\n",
    "\n",
    "  # funding rate snapshot\n",
    "  python -m src.hedge_mvp.cli funding --perp BTC/USDT:USDT --limit 200\n",
    "\n",
    "  # paper rebalancer (testnet, dry-run logs)\n",
    "  python -m src.hedge_mvp.cli paper --symbol BTC/USDT --perp BTC/USDT:USDT --timeframe 1h --limit 1000 --rebalance hourly --iterations 3 --sleep 60\n",
    "\n",
    "  # paper rebalancer + XGB scaling (requires xgboost)\n",
    "  python -m src.hedge_mvp.cli paper --symbol BTC/USDT --perp BTC/USDT:USDT --timeframe 1h --limit 1500 --xgb --rebalance hourly --iterations 3 --sleep 60\n",
    "\"\"\"\n",
    "import argparse, os, json, datetime as dt, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ccxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35749c7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from .core import (\n",
    "    ensure_dir, fetch_ohlcv, fetch_funding_rates, align_close, compute_log_returns,\n",
    "    estimate_ols_hedge_ratio, backtest_static_hedge, sharpe_ratio, max_drawdown_from_returns,\n",
    "    infer_periods_per_year, plot_series, plot_cumlogret, HedgeResults,\n",
    "    build_ml_vol_features, train_xgb_vol_model, predict_next_vol, scale_hedge_ratio,\n",
    "    init_binance, intended_rebalance_log, realized_vol\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da013a",
   "metadata": {},
   "source": [
    "---------- subcommands ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f05817",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cmd_backtest(args):\n",
    "    ex = ccxt.binance()\n",
    "    spot_df = fetch_ohlcv(ex, args.symbol, timeframe=args.timeframe, limit=args.limit)\n",
    "    perp_df = fetch_ohlcv(ex, args.perp, timeframe=args.timeframe, limit=args.limit)\n",
    "    spot_close, perp_close = align_close(spot_df, perp_df)\n",
    "    r_spot = compute_log_returns(spot_close)\n",
    "    r_perp = compute_log_returns(perp_close)\n",
    "\n",
    "    beta = estimate_ols_hedge_ratio(r_spot, r_perp)\n",
    "    r_spot_al, r_hedged = backtest_static_hedge(r_spot, r_perp, beta)\n",
    "\n",
    "    var_spot = float(r_spot_al.var())\n",
    "    var_hedged = float(r_hedged.var())\n",
    "    variance_reduction = 1.0 - (var_hedged/var_spot) if var_spot>0 else 0.0\n",
    "    periods = infer_periods_per_year(args.timeframe)\n",
    "    sr_spot = sharpe_ratio(r_spot_al, periods)\n",
    "    sr_hedged = sharpe_ratio(r_hedged, periods)\n",
    "    mdd_spot = max_drawdown_from_returns(r_spot_al)\n",
    "    mdd_hedged = max_drawdown_from_returns(r_hedged)\n",
    "\n",
    "    # outdir\n",
    "    sym = args.symbol.replace(\"/\",\"\").replace(\":\",\"\")\n",
    "    ts = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    outdir = os.path.join(\"runs\", sym, \"hedge_mvp\", ts)\n",
    "    ensure_dir(outdir)\n",
    "\n",
    "    # save\n",
    "    pd.DataFrame({\"spot_close\": spot_close, \"perp_close\": perp_close}).to_csv(os.path.join(outdir, \"prices.csv\"))\n",
    "    pd.DataFrame({\"r_spot\": r_spot_al, \"r_hedged\": r_hedged}).to_csv(os.path.join(outdir, \"returns.csv\"))\n",
    "    with open(os.path.join(outdir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump({\n",
    "            \"timeframe\": args.timeframe, \"samples\": int(len(r_spot_al)),\n",
    "            \"hedge_ratio\": float(beta),\n",
    "            \"variance_spot\": var_spot, \"variance_hedged\": var_hedged,\n",
    "            \"variance_reduction\": variance_reduction,\n",
    "            \"sharpe_spot\": sr_spot, \"sharpe_hedged\": sr_hedged,\n",
    "            \"maxdd_spot\": mdd_spot, \"maxdd_hedged\": mdd_hedged\n",
    "        }, f, indent=2)\n",
    "\n",
    "    if args.plot:\n",
    "        plot_series(spot_close, perp_close, outdir)\n",
    "        plot_cumlogret(r_spot_al, r_hedged, outdir)\n",
    "\n",
    "    print(\"=== Backtest Summary ===\")\n",
    "    print(f\"Outdir: {outdir}\")\n",
    "    print(f\"Hedge Ratio (β): {beta:.4f}\")\n",
    "    print(f\"Variance Reduction: {variance_reduction:.2%}\")\n",
    "    print(f\"Sharpe Spot/Hedged: {sr_spot:.3f} / {sr_hedged:.3f}\")\n",
    "    print(f\"MaxDD  Spot/Hedged: {mdd_spot:.2%} / {mdd_hedged:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58cdfd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cmd_funding(args):\n",
    "    ex = ccxt.binance()\n",
    "    df = fetch_funding_rates(ex, args.perp, limit=args.limit)\n",
    "    sym = args.perp.replace(\"/\",\"\").replace(\":\",\"\")\n",
    "    ts = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    outdir = os.path.join(\"runs\", sym, \"hedge_mvp\", ts)\n",
    "    ensure_dir(outdir)\n",
    "    path = os.path.join(outdir, \"funding_rates.csv\")\n",
    "    df.to_csv(path)\n",
    "    print(f\"Saved funding rates to: {path} (rows={len(df)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae68f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cmd_paper(args):\n",
    "    # testnet futures client (dry-run unless --execute)\n",
    "    ex = init_binance(\n",
    "        testnet=True,\n",
    "        api_key=os.getenv(\"BINANCE_TESTNET_API_KEY\"),\n",
    "        secret=os.getenv(\"BINANCE_TESTNET_SECRET\"),\n",
    "    )\n",
    "\n",
    "    sym = args.symbol.replace(\"/\",\"\").replace(\":\",\"\")\n",
    "    ts_root = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    outroot = os.path.join(\"runs\", sym, \"hedge_mvp\", ts_root)\n",
    "    ensure_dir(outroot)\n",
    "    log_path = os.path.join(outroot, \"paper_rebalance_log.jsonl\")\n",
    "\n",
    "    # initial data & model\n",
    "    spot_df = fetch_ohlcv(ccxt.binance(), args.symbol, timeframe=args.timeframe, limit=args.limit)\n",
    "    perp_df = fetch_ohlcv(ccxt.binance(), args.perp, timeframe=args.timeframe, limit=args.limit)\n",
    "    spot_close, perp_close = align_close(spot_df, perp_df)\n",
    "    r_spot = compute_log_returns(spot_close)\n",
    "    r_perp = compute_log_returns(perp_close)\n",
    "    beta = estimate_ols_hedge_ratio(r_spot, r_perp)\n",
    "\n",
    "    model = None\n",
    "    features = None\n",
    "    vol_low = 0.0\n",
    "    vol_high = 0.0\n",
    "    if args.xgb:\n",
    "        df_feat = build_ml_vol_features(r_spot, 48)\n",
    "        if len(df_feat) > 200:\n",
    "            model, features = train_xgb_vol_model(df_feat)\n",
    "            # Calibrate bounds from recent realized vol\n",
    "            recent_vol = df_feat[\"target_vol\"].tail(500)\n",
    "            vol_low = float(np.nanpercentile(recent_vol, 20))\n",
    "            vol_high = float(np.nanpercentile(recent_vol, 80))\n",
    "        else:\n",
    "            print(\"Not enough data to train XGB; running without ML scaling.\")\n",
    "\n",
    "    # simple loop: recompute beta each iteration, scale with ML if enabled\n",
    "    for i in range(int(args.iterations)):\n",
    "        # refresh data window\n",
    "        spot_df = fetch_ohlcv(ccxt.binance(), args.symbol, timeframe=args.timeframe, limit=args.limit)\n",
    "        perp_df = fetch_ohlcv(ccxt.binance(), args.perp, timeframe=args.timeframe, limit=args.limit)\n",
    "        spot_close, perp_close = align_close(spot_df, perp_df)\n",
    "        r_spot = compute_log_returns(spot_close)\n",
    "        r_perp = compute_log_returns(perp_close)\n",
    "        beta = estimate_ols_hedge_ratio(r_spot, r_perp)\n",
    "\n",
    "        scaled_beta = beta\n",
    "        pred_vol = None\n",
    "        if args.xgb and model is not None:\n",
    "            df_feat = build_ml_vol_features(r_spot, 48)\n",
    "            latest_row = df_feat.iloc[-1]\n",
    "            pred_vol = predict_next_vol(model, features, latest_row)\n",
    "            scaled_beta = scale_hedge_ratio(beta, pred_vol, vol_low, vol_high,\n",
    "                                            scale_min=args.scale_min, scale_max=args.scale_max)\n",
    "\n",
    "        # In a real system, we would read current perp position and compute delta to target.\n",
    "        # Here we only LOG the intended order (dry-run) unless --execute is passed.\n",
    "        payload = {\n",
    "            \"ts\": dt.datetime.utcnow().isoformat(),\n",
    "            \"symbol_spot\": args.symbol,\n",
    "            \"symbol_perp\": args.perp,\n",
    "            \"timeframe\": args.timeframe,\n",
    "            \"beta\": float(beta),\n",
    "            \"scaled_beta\": float(scaled_beta),\n",
    "            \"pred_vol\": None if pred_vol is None else float(pred_vol),\n",
    "            \"note\": \"dry-run (no order placed)\" if not args.execute else \"execute requested (not implemented)\"\n",
    "        }\n",
    "        intended_rebalance_log(log_path, payload)\n",
    "        print(f\"[{i+1}/{args.iterations}] logged target hedge β={beta:.4f}, scaled={scaled_beta:.4f}  -> {log_path}\")\n",
    "\n",
    "        # sleep until next rebalance tick\n",
    "        time.sleep(float(args.sleep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2e1bc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Hedge MVP CLI\")\n",
    "    sub = ap.add_subparsers(dest=\"cmd\", required=True)\n",
    "\n",
    "    # backtest\n",
    "    b = sub.add_parser(\"backtest\")\n",
    "    b.add_argument(\"--symbol\", default=\"BTC/USDT\")\n",
    "    b.add_argument(\"--perp\", default=\"BTC/USDT:USDT\")\n",
    "    b.add_argument(\"--timeframe\", default=\"1h\")\n",
    "    b.add_argument(\"--limit\", type=int, default=1500)\n",
    "    b.add_argument(\"--plot\", action=\"store_true\")\n",
    "    b.set_defaults(func=cmd_backtest)\n",
    "\n",
    "    # funding snapshot\n",
    "    f = sub.add_parser(\"funding\")\n",
    "    f.add_argument(\"--perp\", default=\"BTC/USDT:USDT\")\n",
    "    f.add_argument(\"--limit\", type=int, default=200)\n",
    "    f.set_defaults(func=cmd_funding)\n",
    "\n",
    "    # paper rebalancer\n",
    "    p = sub.add_parser(\"paper\")\n",
    "    p.add_argument(\"--symbol\", default=\"BTC/USDT\")\n",
    "    p.add_argument(\"--perp\", default=\"BTC/USDT:USDT\")\n",
    "    p.add_argument(\"--timeframe\", default=\"1h\")\n",
    "    p.add_argument(\"--limit\", type=int, default=1500)\n",
    "    p.add_argument(\"--rebalance\", choices=[\"hourly\",\"daily\"], default=\"hourly\")\n",
    "    p.add_argument(\"--iterations\", type=int, default=3, help=\"how many rebalance cycles to run\")\n",
    "    p.add_argument(\"--sleep\", type=float, default=60, help=\"seconds between iterations\")\n",
    "    p.add_argument(\"--xgb\", action=\"store_true\", help=\"enable XGBoost vol trigger to scale hedge\")\n",
    "    p.add_argument(\"--scale_min\", type=float, default=0.3)\n",
    "    p.add_argument(\"--scale_max\", type=float, default=1.2)\n",
    "    p.add_argument(\"--execute\", action=\"store_true\", help=\"PLACE ORDERS (not implemented yet) – for now only logs\")\n",
    "    p.set_defaults(func=cmd_paper)\n",
    "\n",
    "    args = ap.parse_args()\n",
    "    args.func(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8886f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "jupytext,text_representation,kernelspec"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
