{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f78653e",
   "metadata": {},
   "source": [
    "# Features Preview + Leakage Checks\n",
    "Quick look at processed features, basic target wiring, feature importance, and simple leakage checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf835ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, math, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../../..\"))\n",
    "DATA_PROCESSED = os.path.join(ROOT, \"data\", \"processed\")\n",
    "REPORT_FIGS = os.path.join(ROOT, \"reports\", \"figures\")\n",
    "os.makedirs(REPORT_FIGS, exist_ok=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8fd9e3",
   "metadata": {},
   "source": [
    "## 1) Load processed feature set\n",
    "Loads the **first** `.parquet` in `data/processed` (adjust if you want a specific file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parqs = [f for f in os.listdir(DATA_PROCESSED) if f.endswith(\".parquet\")]\n",
    "if not parqs:\n",
    "    raise FileNotFoundError(\"No parquet in data/processed. Run a pipeline (e.g., make quick-features).\")\n",
    "path = os.path.join(DATA_PROCESSED, sorted(parqs)[0])\n",
    "df = pd.read_parquet(path)\n",
    "print(\"Loaded:\", path, \"shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43802b81",
   "metadata": {},
   "source": [
    "## 2) Identify time index, target, and features\n",
    "Heuristics: `timestamp` (or `date`) for time, and common target names like `y`, `target`, `vol_target`, `ret_hXX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b04ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time index\n",
    "time_col = None\n",
    "for c in [\"timestamp\", \"date\", \"time\"]:\n",
    "    if c in df.columns:\n",
    "        time_col = c\n",
    "        break\n",
    "if time_col is None:\n",
    "    raise ValueError(\"No timestamp/date column found. Add one of ['timestamp','date','time'].\")\n",
    "\n",
    "df[time_col] = pd.to_datetime(df[time_col], utc=False)\n",
    "df = df.sort_values(time_col).reset_index(drop=True)\n",
    "\n",
    "# Target column\n",
    "target_candidates = [c for c in df.columns if re.search(r\"^(y|target|vol_?target|ret_h\\d+)$\", c)]\n",
    "target_col = target_candidates[0] if target_candidates else None\n",
    "\n",
    "# If no explicit target, fall back to forward abs-return over horizon=12 (approx)\n",
    "if target_col is None:\n",
    "    ret_cols = [c for c in df.columns if c.startswith(\"ret_\")]\n",
    "    if ret_cols:\n",
    "        base = ret_cols[0]\n",
    "        df[\"y_proxy\"] = df[base].rolling(12).apply(lambda x: np.sqrt(np.sum(np.square(x))), raw=True)\n",
    "        target_col = \"y_proxy\"\n",
    "        print(\"No explicit target found â†’ using proxy:\", target_col)\n",
    "    else:\n",
    "        raise ValueError(\"No target found and no return cols to build proxy. Please add a target.\")\n",
    "\n",
    "# Feature set: exclude time & any known labels\n",
    "exclude = {time_col, target_col}\n",
    "meta_like = {c for c in df.columns if c.lower() in {\"symbol\",\"asset\"}}\n",
    "features = [c for c in df.columns if c not in exclude.union(meta_like)]\n",
    "\n",
    "print(\"time_col:\", time_col)\n",
    "print(\"target_col:\", target_col)\n",
    "print(\"n_features:\", len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b654bd5",
   "metadata": {},
   "source": [
    "## 3) Basic sanity & leakage checks\n",
    "- Nulls\n",
    "- Duplicate columns\n",
    "- Exact leaks (features identical to target)\n",
    "- Suspicious names (e.g., *future*, *target*, *pred*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6820a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df[features+[target_col]].isna().sum().sort_values(ascending=False)\n",
    "dupe_cols = []\n",
    "seen = {}\n",
    "for c in features:\n",
    "    sig = (df[c].astype(\"float64\").fillna(-1234567.89).values.tobytes())\n",
    "    if sig in seen:\n",
    "        dupe_cols.append((c, seen[sig]))\n",
    "    else:\n",
    "        seen[sig] = c\n",
    "\n",
    "exact_leaks = [c for c in features if df[c].equals(df[target_col])]\n",
    "suspect_by_name = [c for c in features if re.search(r\"(future|lead|target|pred|label)\", c, re.I)]\n",
    "\n",
    "print(\"Top nulls:\\n\", nulls.head(10))\n",
    "print(\"Duplicate feature pairs:\", dupe_cols[:5])\n",
    "print(\"Exact leaks:\", exact_leaks)\n",
    "print(\"Suspicious names:\", suspect_by_name[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e493e3df",
   "metadata": {},
   "source": [
    "## 4) Train/valid split (time-based) + quick model\n",
    "Use a small RF just to get rough feature importances (XGB optional but RF is dependency-light)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_cols = [c for c in features if c not in set(x for x,_ in dupe_cols)]\n",
    "X = df[clean_cols].select_dtypes(include=[np.number]).fillna(0.0).values\n",
    "y = df[target_col].values\n",
    "\n",
    "# Last 20% as validation\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_tr, X_va = X[:split_idx], X[split_idx:]\n",
    "y_tr, y_va = y[:split_idx], y[split_idx:]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=8, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_tr, y_tr)\n",
    "pred = rf.predict(X_va)\n",
    "\n",
    "rmse = mean_squared_error(y_va, pred, squared=False)\n",
    "r2 = r2_score(y_va, pred)\n",
    "print(\"Valid RMSE:\", rmse, \"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6608f32",
   "metadata": {},
   "source": [
    "## 5) Feature importance & quick plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.Series(rf.feature_importances_, index=df[clean_cols].select_dtypes(include=[np.number]).columns)\n",
    "imp = imp.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.bar(imp.index[:25], imp.values[:25])\n",
    "plt.xticks(rotation=75, ha=\"right\")\n",
    "plt.title(\"Top 25 Feature Importances (RF)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORT_FIGS, \"feature_importance_rf_top25.png\"))\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.plot(df[time_col].iloc[split_idx:], y_va, label=\"actual\")\n",
    "plt.plot(df[time_col].iloc[split_idx:], pred, label=\"pred\")\n",
    "plt.title(\"Validation: Actual vs Pred (time series)\")\n",
    "plt.xlabel(\"Time\"); plt.ylabel(target_col)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORT_FIGS, \"valid_actual_vs_pred.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393b8af",
   "metadata": {},
   "source": [
    "## 6) Save quick report (JSON)\n",
    "Includes basic stats and the top importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46146d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {\n",
    "    \"dataset\": os.path.basename(path),\n",
    "    \"rows\": int(df.shape[0]),\n",
    "    \"cols\": int(df.shape[1]),\n",
    "    \"time_start\": df[time_col].min().isoformat(),\n",
    "    \"time_end\": df[time_col].max().isoformat(),\n",
    "    \"target\": target_col,\n",
    "    \"valid_rmse\": float(rmse),\n",
    "    \"valid_r2\": float(r2),\n",
    "    \"exact_leaks\": exact_leaks,\n",
    "    \"suspect_by_name\": suspect_by_name[:20],\n",
    "    \"top_importances\": imp.head(30).to_dict(),\n",
    "}\n",
    "out_json = os.path.join(REPORT_FIGS, \"features_preview_report.json\")\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(\"Saved report:\", out_json)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python",
   "notebook_metadata_filter": "jupytext,text_representation,kernelspec"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
