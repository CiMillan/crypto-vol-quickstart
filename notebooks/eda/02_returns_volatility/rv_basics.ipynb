{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e9e8a5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Plot defaults (project-wide)\n",
    "This cell ensures consistent Matplotlib styling and date axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 'configs' importable from notebooks (.ipynb or .py)\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "try:\n",
    "    HERE = Path(__file__).parent\n",
    "except NameError:\n",
    "    HERE = Path.cwd()\n",
    "ROOT = (HERE / \"../../..\").resolve()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "from configs.plots.mpl_defaults import use_mpl_defaults, format_date_axis\n",
    "use_mpl_defaults()\n",
    "\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     cell_metadata_filter: -all\n",
    "#     formats: ipynb,py:percent\n",
    "#     notebook_metadata_filter: jupytext,text_representation,kernelspec\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.17.3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598e358",
   "metadata": {},
   "source": [
    "# Returns & Realized Volatility (RV) + HAR-RV Prep\n",
    "This notebook builds basic returns, daily realized volatility, and HAR-RV regressors.\n",
    "Works with OHLCV data in `data/raw/` (CSV or Parquet) with at least: `timestamp`, `close`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../../..\"))\n",
    "DATA_RAW = os.path.join(ROOT, \"data\", \"raw\")\n",
    "DATA_INTERIM = os.path.join(ROOT, \"data\", \"interim\")\n",
    "DATA_PROCESSED = os.path.join(ROOT, \"data\", \"processed\")\n",
    "REPORT_FIGS = os.path.join(ROOT, \"reports\", \"figures\")\n",
    "\n",
    "os.makedirs(DATA_INTERIM, exist_ok=True)\n",
    "os.makedirs(DATA_PROCESSED, exist_ok=True)\n",
    "os.makedirs(REPORT_FIGS, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f92f9",
   "metadata": {},
   "source": [
    "## 1) Load data (first file in `data/raw/`)\n",
    "Supports CSV (expects `timestamp` parse) or Parquet. Ensures sorted by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = [f for f in os.listdir(DATA_RAW) if f.lower().endswith((\".csv\",\".parquet\"))]\n",
    "if not cands:\n",
    "    raise FileNotFoundError(\"Drop OHLCV into data/raw (CSV or Parquet with 'timestamp','close').\")\n",
    "path = os.path.join(DATA_RAW, cands[0])\n",
    "\n",
    "if path.endswith(\".csv\"):\n",
    "    df = pd.read_csv(path, parse_dates=[\"timestamp\"])\n",
    "else:\n",
    "    df = pd.read_parquet(path)\n",
    "df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# Ensure tz-naive for resampling compatibility\n",
    "if pd.api.types.is_datetime64_any_dtype(df[\"timestamp\"]):\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=False)\n",
    "else:\n",
    "    raise ValueError(\"Column 'timestamp' must be datetime-like.\")\n",
    "\n",
    "df = df[[\"timestamp\",\"close\"]].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c9fdf",
   "metadata": {},
   "source": [
    "## 2) Intraday returns and daily Realized Volatility (RV)\n",
    "- Compute log returns at native frequency\n",
    "- Aggregate to daily RV = sqrt( sum intraday r_t^2 ) and annualize with sqrt(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e291d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"logret\"] = np.log(df[\"close\"]).diff()\n",
    "df[\"date\"] = df[\"timestamp\"].dt.date\n",
    "\n",
    "# Daily realized variance and volatility\n",
    "rv_daily = (\n",
    "    df.dropna(subset=[\"logret\"])\n",
    "      .groupby(\"date\")[\"logret\"]\n",
    "      .apply(lambda x: np.sqrt((x**2).sum()))  # daily RV (not annualized)\n",
    "      .to_frame(name=\"RV\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Annualize daily RV (sqrt(365) factor). Note: RV here is already sqrt of variance.\n",
    "rv_daily[\"RV_ann\"] = rv_daily[\"RV\"] * math.sqrt(365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a3d24",
   "metadata": {},
   "source": [
    "## 3) Rolling stats & sanity checks\n",
    "Create rolling (5d, 22d) means of RV and simple close-to-close daily vol proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325468c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close-to-close daily returns (from last obs each day)\n",
    "daily_close = df.set_index(\"timestamp\")[\"close\"].resample(\"1D\").last().dropna()\n",
    "cc_ret = np.log(daily_close).diff().dropna()\n",
    "cc_vol_ann = cc_ret.rolling(22).std() * math.sqrt(252)\n",
    "\n",
    "rv_series = rv_daily.set_index(pd.to_datetime(rv_daily[\"date\"]))[\"RV_ann\"]\n",
    "rv_df = pd.DataFrame({\n",
    "    \"RV_ann\": rv_series,\n",
    "    \"RV_5d\": rv_series.rolling(5).mean(),\n",
    "    \"RV_22d\": rv_series.rolling(22).mean(),\n",
    "    \"CC_vol_ann_22d\": cc_vol_ann.reindex(rv_series.index)\n",
    "}).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8675d",
   "metadata": {},
   "source": [
    "## 4) HAR-RV regressors (Corsi, 2009 style)\n",
    "RV_t = β0 + βd * RV_{t-1} + βw * mean(RV_{t-5..t-1}) + βm * mean(RV_{t-22..t-1}) + ε_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7006ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "har = pd.DataFrame(index=rv_series.index)\n",
    "har[\"RV_t\"] = rv_series\n",
    "har[\"RV_d\"] = rv_series.shift(1)\n",
    "har[\"RV_w\"] = rv_series.rolling(5).mean().shift(1)\n",
    "har[\"RV_m\"] = rv_series.rolling(22).mean().shift(1)\n",
    "har = har.dropna().copy()\n",
    "\n",
    "# Simple OLS via numpy (avoids extra deps)\n",
    "X = np.column_stack([\n",
    "    np.ones(len(har)),\n",
    "    har[\"RV_d\"].values,\n",
    "    har[\"RV_w\"].values,\n",
    "    har[\"RV_m\"].values\n",
    "])\n",
    "y = har[\"RV_t\"].values\n",
    "beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "har[\"RV_hat\"] = X @ beta\n",
    "\n",
    "coef = dict(beta0=beta[0], beta_d=beta[1], beta_w=beta[2], beta_m=beta[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb90d3",
   "metadata": {},
   "source": [
    "## 5) Quick visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da003c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(rv_df.index, rv_df[\"RV_ann\"])\n",
    "plt.title(\"Daily Realized Volatility (annualized)\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"RV_ann\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORT_FIGS, \"rv_daily_ann.png\"))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(har.index, har[\"RV_t\"], label=\"RV_t\")\n",
    "plt.plot(har.index, har[\"RV_hat\"], label=\"HAR fit\")\n",
    "plt.title(\"HAR-RV: Actual vs Fitted\")\n",
    "plt.xlabel(\"Date\"); plt.ylabel(\"RV (annualized)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORT_FIGS, \"har_rv_fit.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ed4b2",
   "metadata": {},
   "source": [
    "## 6) Save outputs\n",
    "- `data/interim/rv_daily.parquet`: daily RV (ann.)\n",
    "- `data/processed/har_rv_features.parquet`: features + fitted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_daily_out = os.path.join(DATA_INTERIM, \"rv_daily.parquet\")\n",
    "har_out = os.path.join(DATA_PROCESSED, \"har_rv_features.parquet\")\n",
    "rv_daily.assign(date=pd.to_datetime(rv_daily[\"date\"])).to_parquet(rv_daily_out, index=False)\n",
    "har.reset_index().rename(columns={\"index\":\"date\"}).to_parquet(har_out, index=False)\n",
    "\n",
    "print(\"Saved:\", rv_daily_out)\n",
    "print(\"Saved:\", har_out)\n",
    "print(\"HAR coefficients:\", coef)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python",
   "notebook_metadata_filter": "jupytext,text_representation,kernelspec"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
