{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7896c558-1b74-40ff-9d21-421db496dfef",
   "metadata": {},
   "source": [
    "# Hedge MVP — Step-by-step Tutorial (Spot + Perp, OLS Hedge, Funding, ML Scaling)\n",
    "\n",
    "**Goal:** running each function in isolation, checking the output, and visualizing as much as possible. This notebook uses your module `src/hedge_mvp/core.py` as the single source of truth.\n",
    "\n",
    "**Covered:**\n",
    "1. Fetch spot & perp OHLCV (`fetch_ohlcv`)\n",
    "2. Align series (`align_close`)\n",
    "3. Log returns (`compute_log_returns`)\n",
    "4. Hedge ratio via OLS (`estimate_ols_hedge_ratio`)\n",
    "5. Static hedge backtest (`backtest_static_hedge`) + metrics (variance reduction, Sharpe, MaxDD)\n",
    "6. Funding rates (`fetch_funding_rates`) quick QA\n",
    "7. ML features (`build_ml_vol_features`), optional XGB vol prediction, and `scale_hedge_ratio`\n",
    "8. Save artifacts to `runs/.../hedge_mvp_tutorial/<TS>/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e108dd9",
   "metadata": {},
   "source": [
    "## 00) Version diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a244cbb9-ee21-4ca0-8b3b-13f87f409ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.12 (default, Feb  3 2022, 12:04:48) \n",
      "[Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "Executable: /Users/cintiamillan/Desktop/Nova IMS/crypto-vol-quickstart/.venv/bin/python\n",
      "numpy: 1.24.4\n",
      "pandas: 2.0.3\n",
      "matplotlib: 3.7.5\n",
      "statsmodels: 0.14.1\n",
      "ccxt: 4.5.6\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, textwrap\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Executable:\", sys.executable)\n",
    "\n",
    "def _pip_freeze_top(n=10):\n",
    "    out = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"], text=True)\n",
    "    print(\"\\nTop of pip freeze:\\n\", \"\\n\".join(out.splitlines()[:n]))\n",
    "try:\n",
    "    import numpy, pandas, matplotlib, statsmodels, ccxt\n",
    "    print(\"numpy:\", numpy.__version__)\n",
    "    print(\"pandas:\", pandas.__version__)\n",
    "    print(\"matplotlib:\", matplotlib.__version__)\n",
    "    import statsmodels.api as sm; print(\"statsmodels:\", sm.__version__)\n",
    "    import ccxt; print(\"ccxt:\", ccxt.__version__)\n",
    "except Exception as e:\n",
    "    print(\"Import check failed:\", e)\n",
    "    _pip_freeze_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dfda849-6649-4d88-9743-de5ad0319141",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.12\n",
      "Executable: /Users/cintiamillan/Desktop/Nova IMS/crypto-vol-quickstart/.venv/bin/python\n",
      "[+ 0.00s] importing numpy ...\n",
      "[+ 0.00s] numpy 1.24.4 ok\n",
      "[+ 0.00s] importing pandas ...\n",
      "[+ 0.00s] pandas 2.0.3 ok\n",
      "[+ 0.00s] importing matplotlib ...\n",
      "[+ 0.00s] matplotlib 3.7.5 ok\n",
      "[+ 0.00s] importing statsmodels ...\n",
      "[+ 0.00s] statsmodels 0.14.1 ok\n",
      "[+ 0.00s] importing ccxt ...\n",
      "[+ 0.00s] ccxt 4.5.6 ok\n"
     ]
    }
   ],
   "source": [
    "import os, sys, subprocess, time\n",
    "\n",
    "# 1) Speed up matplotlib import (must be set BEFORE importing matplotlib)\n",
    "os.environ.setdefault(\"MPLBACKEND\", \"Agg\")       # non-GUI backend\n",
    "os.environ.setdefault(\"MPLCONFIGDIR\", \".mpl\")    # writable cache in repo\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Executable:\", sys.executable)\n",
    "\n",
    "def t(msg):\n",
    "    print(f\"[+{time.perf_counter()-t0:5.2f}s] {msg}\")\n",
    "\n",
    "try:\n",
    "    t(\"importing numpy ...\");      import numpy as np;            t(f\"numpy {np.__version__} ok\")\n",
    "    t(\"importing pandas ...\");     import pandas as pd;           t(f\"pandas {pd.__version__} ok\")\n",
    "    t(\"importing matplotlib ...\"); import matplotlib;             t(f\"matplotlib {matplotlib.__version__} ok\")\n",
    "    t(\"importing statsmodels ...\");import statsmodels.api as sm;  t(f\"statsmodels {sm.__version__} ok\")\n",
    "    t(\"importing ccxt ...\");       import ccxt;                   t(f\"ccxt {ccxt.__version__} ok\")\n",
    "except Exception as e:\n",
    "    print(\"Import check failed:\", repr(e))\n",
    "    # MUCH faster than 'pip freeze':\n",
    "    try:\n",
    "        out = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"list\", \"--format=freeze\"], text=True, timeout=10)\n",
    "        print(\"\\nTop of pip list:\\n\", \"\\n\".join(out.splitlines()[:10]))\n",
    "    except Exception as ee:\n",
    "        print(\"pip list also failed:\", repr(ee))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023fc67-65d6-4efa-a16b-5535b7e47948",
   "metadata": {},
   "source": [
    "## 0) Setup & sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e85b9e8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Project imports — our core functions live here\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhedge_mvp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     ensure_dir, fetch_ohlcv, fetch_funding_rates, align_close, compute_log_returns,\n\u001b[1;32m     12\u001b[0m     estimate_ols_hedge_ratio, backtest_static_hedge, sharpe_ratio, max_drawdown_from_returns,\n\u001b[1;32m     13\u001b[0m     infer_periods_per_year, plot_series, plot_cumlogret,\n\u001b[1;32m     14\u001b[0m     build_ml_vol_features, train_xgb_vol_model, predict_next_vol, scale_hedge_ratio,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Basic display opts\u001b[39;00m\n\u001b[1;32m     18\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.width\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os, json, math, datetime as dt\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Libs for runtime display\n",
    "import importlib, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Project imports — our core functions live here\n",
    "from src.hedge_mvp.core import (\n",
    "    ensure_dir, fetch_ohlcv, fetch_funding_rates, align_close, compute_log_returns,\n",
    "    estimate_ols_hedge_ratio, backtest_static_hedge, sharpe_ratio, max_drawdown_from_returns,\n",
    "    infer_periods_per_year, plot_series, plot_cumlogret,\n",
    "    build_ml_vol_features, train_xgb_vol_model, predict_next_vol, scale_hedge_ratio,\n",
    ")\n",
    "\n",
    "# Basic display opts\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "\n",
    "# Versions (helpful for reproducibility)\n",
    "import ccxt, statsmodels\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"matplotlib:\", plt.matplotlib.__version__)\n",
    "print(\"ccxt:\", ccxt.__version__)\n",
    "print(\"statsmodels:\", statsmodels.__version__)\n",
    "\n",
    "# Try XGBoost (optional)\n",
    "try:\n",
    "    import xgboost\n",
    "    HAS_XGB = True\n",
    "    print(\"xgboost:\", xgboost.__version__)\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "    print(\"xgboost: NOT INSTALLED (ML step will be skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3e7111",
   "metadata": {},
   "source": [
    "## 1) Configuration\n",
    "Pick symbols and timeframe. We start with BTC/USDT and 1h bars for quick iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bdf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOL_SPOT = \"BTC/USDT\"\n",
    "SYMBOL_PERP = \"BTC/USDT:USDT\"   # Binance USD-M perp routing via ccxt.binance()\n",
    "TIMEFRAME   = \"1h\"\n",
    "LIMIT       = 1500              # ~62 days of hourly data\n",
    "\n",
    "# Where tutorial artifacts will be saved\n",
    "RUNS_SYM = SYMBOL_SPOT.replace(\"/\",\"\").replace(\":\",\"\")\n",
    "TS_STR   = dt.datetime.utcnow().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "OUTDIR   = os.path.join(\"runs\", RUNS_SYM, \"hedge_mvp_tutorial\", TS_STR)\n",
    "ensure_dir(OUTDIR)\n",
    "OUTDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23679bc3",
   "metadata": {},
   "source": [
    "## 2) Fetch Spot OHLCV (`fetch_ohlcv`)\n",
    "- Pulls candles via `ccxt.binance().fetch_ohlcv`\n",
    "- Returns a DataFrame indexed by UTC timestamps with columns: open, high, low, close, volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d66827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "ex = ccxt.binance()\n",
    "spot_df = fetch_ohlcv(ex, SYMBOL_SPOT, timeframe=TIMEFRAME, limit=LIMIT)\n",
    "print(\"spot_df shape:\", spot_df.shape)\n",
    "display(spot_df.head(3))\n",
    "display(spot_df.tail(3))\n",
    "print(\"Index tz-aware:\", spot_df.index.tz is not None)\n",
    "print(\"Time span:\", spot_df.index.min(), \"→\", spot_df.index.max())\n",
    "print(\"Any NA? \", spot_df.isna().any().to_dict())\n",
    "\n",
    "# Visualize spot close\n",
    "plt.figure()\n",
    "spot_df[\"close\"].plot()\n",
    "plt.title(f\"{SYMBOL_SPOT} Close ({TIMEFRAME})\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00928efc",
   "metadata": {},
   "source": [
    "## 3) Fetch Perp OHLCV (`fetch_ohlcv`) and quick QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4939fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perp_df = fetch_ohlcv(ex, SYMBOL_PERP, timeframe=TIMEFRAME, limit=LIMIT)\n",
    "print(\"perp_df shape:\", perp_df.shape)\n",
    "display(perp_df.head(3))\n",
    "display(perp_df.tail(3))\n",
    "print(\"Index tz-aware:\", perp_df.index.tz is not None)\n",
    "print(\"Time span:\", perp_df.index.min(), \"→\", perp_df.index.max())\n",
    "print(\"Any NA? \", perp_df.isna().any().to_dict())\n",
    "\n",
    "# Visualize perp close\n",
    "plt.figure()\n",
    "perp_df[\"close\"].plot()\n",
    "plt.title(f\"{SYMBOL_PERP} Close ({TIMEFRAME})\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4b8c6",
   "metadata": {},
   "source": [
    "## 4) Align series (`align_close`)\n",
    "- Ensures both series share the same timestamps.\n",
    "- We verify lengths & equality of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80df2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_close, perp_close = align_close(spot_df, perp_df)\n",
    "print(\"Aligned lengths:\", len(spot_close), len(perp_close))\n",
    "print(\"Same index?\", spot_close.index.equals(perp_close.index))\n",
    "\n",
    "# Quick overlay plot\n",
    "plt.figure()\n",
    "spot_close.plot(label=\"Spot Close\")\n",
    "perp_close.plot(label=\"Perp Close\")\n",
    "plt.title(\"Aligned Close Prices\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f5a2a",
   "metadata": {},
   "source": [
    "## 5) Compute log returns (`compute_log_returns`)\n",
    "- We compute `r_t = log(P_t) - log(P_{t-1})` for spot & perp.\n",
    "- Inspect summary stats and simple distribution shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_spot = compute_log_returns(spot_close)\n",
    "r_perp = compute_log_returns(perp_close)\n",
    "\n",
    "# Sanity: aligned after diff\n",
    "aligned = pd.concat([r_spot.rename(\"r_spot\"), r_perp.rename(\"r_perp\")], axis=1, join=\"inner\").dropna()\n",
    "display(aligned.describe(percentiles=[0.01,0.05,0.95,0.99]))\n",
    "\n",
    "# Histograms (separate figures)\n",
    "plt.figure()\n",
    "aligned[\"r_spot\"].hist(bins=50)\n",
    "plt.title(\"Histogram: r_spot\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "aligned[\"r_perp\"].hist(bins=50)\n",
    "plt.title(\"Histogram: r_perp\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Simple autocorrelation check for r_spot (lag-1..5)\n",
    "acs = [aligned[\"r_spot\"].autocorr(lag=k) for k in range(1,6)]\n",
    "print(\"Autocorr r_spot lags 1..5:\", [round(a,4) for a in acs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce58ac",
   "metadata": {},
   "source": [
    "## 6) Estimate hedge ratio via OLS (`estimate_ols_hedge_ratio`)\n",
    "- Regression: spot returns ~ perp returns (with intercept)\n",
    "- β (the slope) is the **hedge ratio** to minimize variance of the hedged portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91755cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = estimate_ols_hedge_ratio(r_spot, r_perp)\n",
    "print(\"Estimated OLS hedge ratio (β):\", round(beta, 6))\n",
    "\n",
    "# (Optional) peek at regression summary by re-running manually\n",
    "# import statsmodels.api as sm\n",
    "# y = aligned[\"r_spot\"].values\n",
    "# X = sm.add_constant(aligned[\"r_perp\"].values)\n",
    "# model = sm.OLS(y, X).fit()\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a759088",
   "metadata": {},
   "source": [
    "## 7) Backtest static hedge (`backtest_static_hedge`) + metrics\n",
    "- Construct hedged returns: `r_hedged = r_spot - β * r_perp`\n",
    "- Report variance reduction, Sharpe, Max Drawdown\n",
    "- Visualize cumulative **log** returns (additive over time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d82aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sp_al, r_hedged = backtest_static_hedge(r_spot, r_perp, beta)\n",
    "\n",
    "var_spot = float(r_sp_al.var())\n",
    "var_hedged = float(r_hedged.var())\n",
    "variance_reduction = 1.0 - (var_hedged/var_spot) if var_spot>0 else 0.0\n",
    "\n",
    "periods = infer_periods_per_year(TIMEFRAME)\n",
    "sr_spot = sharpe_ratio(r_sp_al, periods)\n",
    "sr_hedged = sharpe_ratio(r_hedged, periods)\n",
    "mdd_spot = max_drawdown_from_returns(r_sp_al)\n",
    "mdd_hedged = max_drawdown_from_returns(r_hedged)\n",
    "\n",
    "print(\"Variance (Spot):   \", f\"{var_spot:.6e}\")\n",
    "print(\"Variance (Hedged): \", f\"{var_hedged:.6e}\")\n",
    "print(\"Variance reduction:\", f\"{variance_reduction:.2%}\")\n",
    "print(\"Sharpe Spot/Hedged:\", round(sr_spot,3), \"/\", round(sr_hedged,3))\n",
    "print(\"MaxDD  Spot/Hedged:\", f\"{mdd_spot:.2%}\", \"/\", f\"{mdd_hedged:.2%}\")\n",
    "\n",
    "# Cumulative log returns\n",
    "plt.figure()\n",
    "r_sp_al.cumsum().plot(label=\"Spot log-return cum\")\n",
    "r_hedged.cumsum().plot(label=\"Hedged log-return cum\")\n",
    "plt.title(\"Cumulative Log Returns — Spot vs Hedged\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5175f",
   "metadata": {},
   "source": [
    "## 8) Funding rates (`fetch_funding_rates`)\n",
    "- Snapshot of recent perp funding; useful context for regimes & hedge costs.\n",
    "- Not all ccxt routes expose history; this returns an empty DF if unsupported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b776671",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_df = fetch_funding_rates(ex, SYMBOL_PERP, limit=200)\n",
    "print(\"fund_df shape:\", fund_df.shape)\n",
    "display(fund_df.head(3))\n",
    "\n",
    "# If it has a \"fundingRate\" column, quick plot:\n",
    "if \"fundingRate\" in fund_df.columns:\n",
    "    plt.figure()\n",
    "    fund_df[\"fundingRate\"].astype(float).plot()\n",
    "    plt.title(\"Funding Rate (recent)\")\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d621a",
   "metadata": {},
   "source": [
    "## 9) ML features + optional XGBoost vol prediction & hedge scaling\n",
    "- Build simple volatility features (`build_ml_vol_features`)\n",
    "- If xgboost is installed, train a tiny model to predict next-step vol proxy\n",
    "- Map predicted vol to a scale in [scale_min, scale_max] and apply to β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = build_ml_vol_features(r_sp_al, 48)\n",
    "print(\"Feature DF shape:\", feat_df.shape)\n",
    "display(feat_df.head(5))\n",
    "\n",
    "scale_min, scale_max = 0.3, 1.2\n",
    "pred_vol = None\n",
    "scaled_beta = beta\n",
    "\n",
    "if HAS_XGB and len(feat_df) > 200:\n",
    "    model, features = train_xgb_vol_model(feat_df)\n",
    "    latest_row = feat_df.iloc[-1]\n",
    "    pred_vol = predict_next_vol(model, features, latest_row)\n",
    "    # Calibrate rough bounds from recent target vols\n",
    "    recent = feat_df[\"target_vol\"].tail(500)\n",
    "    vol_low  = float(np.nanpercentile(recent, 20)) if recent.size>0 else 0.0\n",
    "    vol_high = float(np.nanpercentile(recent, 80)) if recent.size>0 else 1.0\n",
    "    scaled_beta = scale_hedge_ratio(beta, pred_vol, vol_low, vol_high, scale_min=scale_min, scale_max=scale_max)\n",
    "    print(\"Predicted next-step vol:\", None if pred_vol is None else round(float(pred_vol), 6))\n",
    "    print(\"Scaled β:\", round(scaled_beta, 6))\n",
    "else:\n",
    "    print(\"Skipping ML scaling (xgboost missing or not enough rows).\")\n",
    "\n",
    "# Visualize the scaling effect across a grid of hypothetical vols\n",
    "if HAS_XGB:\n",
    "    grid = np.linspace(0.0, float(feat_df[\"target_vol\"].quantile(0.99) if \"target_vol\" in feat_df else 0.01), 50)\n",
    "    scaled_vals = []\n",
    "    vol_low  = float(np.nanpercentile(feat_df[\"target_vol\"], 20)) if \"target_vol\" in feat_df else 0.0\n",
    "    vol_high = float(np.nanpercentile(feat_df[\"target_vol\"], 80)) if \"target_vol\" in feat_df else 1.0\n",
    "    for v in grid:\n",
    "        scaled_vals.append(scale_hedge_ratio(beta, v, vol_low, vol_high, scale_min, scale_max))\n",
    "    plt.figure()\n",
    "    pd.Series(scaled_vals, index=grid).plot()\n",
    "    plt.title(\"Hedge scaling vs hypothetical vol\")\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d2be2a",
   "metadata": {},
   "source": [
    "## 10) Save artifacts to disk\n",
    "- Prices & returns CSVs\n",
    "- Metrics JSON\n",
    "- Plots PNG (already displayed above)\n",
    "- Funding snapshot (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ba965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prices\n",
    "pd.DataFrame({\"spot_close\": spot_close, \"perp_close\": perp_close}).to_csv(os.path.join(OUTDIR, \"prices.csv\"))\n",
    "# Returns\n",
    "pd.DataFrame({\"r_spot\": r_sp_al, \"r_hedged\": r_hedged}).to_csv(os.path.join(OUTDIR, \"returns.csv\"))\n",
    "# Metrics\n",
    "with open(os.path.join(OUTDIR, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"timeframe\": TIMEFRAME, \"samples\": int(len(r_sp_al)),\n",
    "        \"hedge_ratio\": float(beta),\n",
    "        \"scaled_beta\": float(scaled_beta),\n",
    "        \"variance_spot\": float(var_spot), \"variance_hedged\": float(var_hedged),\n",
    "        \"variance_reduction\": float(variance_reduction),\n",
    "        \"sharpe_spot\": float(sr_spot), \"sharpe_hedged\": float(sr_hedged),\n",
    "        \"maxdd_spot\": float(mdd_spot), \"maxdd_hedged\": float(mdd_hedged)\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Funding (optional)\n",
    "if isinstance(fund_df, pd.DataFrame) and not fund_df.empty:\n",
    "    fund_df.to_csv(os.path.join(OUTDIR, \"funding_rates.csv\"))\n",
    "\n",
    "print(\"Saved artifacts to:\", OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4b09f",
   "metadata": {},
   "source": [
    "## 11) Where to go next\n",
    "- Use `make hedge-paper` for a **dry-run rebalancer** that logs intended hedge ratios per cycle.\n",
    "- Later: wire **testnet orders** (USD-M perps) with strict guardrails (min notional, leverage caps, kill-switch).\n",
    "- For the PhD: expand ML pipeline (XGBoost baseline → HAR-RV/MIDAS → LSTM/Transformer), add **regime filters**, and run **Diebold–Mariano** tests."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "jupytext,text_representation,kernelspec"
  },
  "kernelspec": {
   "display_name": "crypto-vol (.venv)",
   "language": "python",
   "name": "crypto-vol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
